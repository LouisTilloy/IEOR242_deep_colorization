{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "data = tfds.load(\"cifar10\")\n",
    "train, test = data[\"train\"], data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24 random images from cifar10\n",
    "list_images = [data[\"image\"] for data in train.shuffle(20000).take(4 * 6)]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for index, image in enumerate(list_images):\n",
    "    plt.subplot(4, 6, index + 1)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "plt.subplot()\n",
    "plt.subplot(1, 2, 1)\n",
    "data = [data for data in train.shuffle(1000).take(1)][0]\n",
    "image = data[\"image\"]\n",
    "plt.imshow(image)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "lab_image = color.rgb2lab(image)\n",
    "plt.imshow((lab_image[:, :, 0]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_values = []\n",
    "b_values = []\n",
    "l_values = []\n",
    "for feature in tqdm(train.shuffle(1000000).take(10000), total=10000):\n",
    "    lab_image = color.rgb2lab(feature[\"image\"])\n",
    "    l_values.append(lab_image[:, :, 0])\n",
    "    a_values.append(lab_image[:, :, 1])\n",
    "    b_values.append(lab_image[:, :, 2])\n",
    "\n",
    "l_values = np.array(l_values).flatten()\n",
    "a_values = np.array(a_values).flatten()\n",
    "b_values = np.array(b_values).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(l_values, bins=200)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(a_values, bins=200)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(b_values, bins=200)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BINS_CUTS = [-100, -50, -25, -15, -10, -5, 0, 5, 10, 15, 25, 50, 100]\n",
    "n_bins = len(BINS_CUTS) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bin_value(bins, value):\n",
    "    cut_0 = bins[0]\n",
    "    for index, cut in enumerate(bins[1:]):\n",
    "        if cut_0 <= value < cut:\n",
    "            return index\n",
    "        cut_0 = cut\n",
    "        \n",
    "    return index\n",
    "\n",
    "def unbin_value(bins, value):\n",
    "    return bins[value]\n",
    "\n",
    "def pre_process(cifar10_data):\n",
    "    image = cifar10_data[\"image\"]\n",
    "    rgb_image = np.array(image)\n",
    "    lab_image = color.rgb2lab(rgb_image)\n",
    "    \n",
    "    # get features (i.e. the luminance)\n",
    "    features = lab_image[:, :, 0:1]\n",
    "    \n",
    "    # get labels (i.e the ab channels)\n",
    "    raw_a, raw_b = lab_image[:, :, 1:2], lab_image[:, :, 2:3]\n",
    "    v_bin_value = np.vectorize(lambda value: bin_value(BINS_CUTS, value))\n",
    "    bins_a = v_bin_value(raw_a)\n",
    "    bins_b = v_bin_value(raw_b)\n",
    "    labels = (bins_a, bins_b)\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def process_output(input_luminance, output_bins):\n",
    "    bins_a, bins_b = output_bins\n",
    "    v_unbin_value = np.vectorize(lambda value: unbin_value(BINS_CUTS, value))\n",
    "    unbins_a = v_unbin_value(bins_a)\n",
    "    unbins_b = v_unbin_value(bins_b)\n",
    "    reconstructed_image = np.stack((input_luminance, unbins_a, unbins_b), axis=2)\n",
    "    #print(reconstructed_image.shape)\n",
    "    rgb_rec_image = color.lab2rgb(reconstructed_image)\n",
    "    return rgb_rec_image\n",
    "\n",
    "data = [data for data in train.shuffle(1000).take(1)][0]\n",
    "new_feature, new_label = pre_process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, data in enumerate(train.shuffle(10000).take(20)):\n",
    "    if index % 2 == 0:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        base_index = 1\n",
    "    else:\n",
    "        base_index = 4\n",
    "        \n",
    "    plt.subplot(1, 5, base_index)\n",
    "    plt.imshow(data[\"image\"])\n",
    "    \n",
    "    new_feature, new_label = pre_process(data)\n",
    "    reconstructed_image = process_output(new_feature, new_label)\n",
    "    plt.subplot(1, 5, base_index + 1)\n",
    "    plt.imshow(reconstructed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_train = tfds.as_numpy(train)\n",
    "def get_dataset():\n",
    "    def aux_generator():\n",
    "        numpy_train = tfds.as_numpy(train)\n",
    "        for data in numpy_train:\n",
    "            yield pre_process(data)\n",
    "    \n",
    "    data = tf.data.Dataset.from_generator(aux_generator,\n",
    "                                          output_types=(np.float32, np.int64))\n",
    "    data = data.shuffle(60000).batch(32)\n",
    "    return data\n",
    "\n",
    "dataset = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # (batch_size, 32, 32, 1) --> (batch_size, 16, 16, 8)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=8, kernel_size=5,\n",
    "                                            strides=(2, 2),\n",
    "                                            padding='same',\n",
    "                                            activation='relu',\n",
    "                                            input_shape=(32, 32, 1))\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # (batch_size, 16, 16, 8) --> (batch_size, 8, 8, 16)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=16, kernel_size=3,\n",
    "                                            strides=(2, 2),\n",
    "                                            padding='same',\n",
    "                                            activation='relu')\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        \n",
    "        # (batch_size, 8, 8, 16)  --> (batch_size, 4, 4, 32)\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=32, kernel_size=3,\n",
    "                                            strides=(2, 2),\n",
    "                                            padding='same',\n",
    "                                            activation='relu')\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # (batch_size, 4, 4, 32) --> (batch_size, 4, 4, 64)\n",
    "        self.conv4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3,\n",
    "                                            strides=(1, 1),\n",
    "                                            padding='same',\n",
    "                                            activation='relu')\n",
    "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # (batch_size, 4, 4, 64) --> (batch_size, 8, 8, 32)\n",
    "        self.deconv1 = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3,\n",
    "                                                       strides=(2, 2),\n",
    "                                                       padding='same',\n",
    "                                                       activation='relu')\n",
    "        self.bn5 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # (batch_size, 8, 8, 32) --> (batch_size, 16, 16, 32)\n",
    "        self.deconv2 = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3,\n",
    "                                                       strides=(2, 2),\n",
    "                                                       padding='same',\n",
    "                                                       activation='relu')\n",
    "        self.bn6 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # (batch_size, 16, 16, 32) --> (batch_size, 32, 32, 32)\n",
    "        self.deconv3 = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3,\n",
    "                                                       strides=(2, 2),\n",
    "                                                       padding='same',\n",
    "                                                       activation='relu')\n",
    "        self.bn7 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # (batch_size, 32, 32, 32) --> (batch_size, 32, 32, n_bins)\n",
    "        self.deconv_a = tf.keras.layers.Conv2DTranspose(filters=n_bins, kernel_size=1,\n",
    "                                                        activation='softmax',\n",
    "                                                        strides=(1, 1))\n",
    "        self.deconv_b = tf.keras.layers.Conv2DTranspose(filters=n_bins, kernel_size=1,\n",
    "                                                        activation='softmax',\n",
    "                                                        strides=(1, 1))\n",
    "        \n",
    "        self.seq_layers = [self.conv1, self.bn1,\n",
    "                           self.conv2, self.bn2,\n",
    "                           self.conv3, self.bn3,\n",
    "                           self.conv4, self.bn4,\n",
    "                           self.deconv1, self.bn5,\n",
    "                           self.deconv2, self.bn6,\n",
    "                           self.deconv3, self.bn7]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.seq_layers:\n",
    "            x = layer(x)\n",
    "        probs_a = self.deconv_a(x)\n",
    "        probs_b = self.deconv_b(x)\n",
    "        return probs_a, probs_b\n",
    "        \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy_a = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy_a')\n",
    "train_accuracy_b = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy_b')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy_a = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy_a')\n",
    "test_accuracy_b = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy_b')\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "@tf.function\n",
    "def train_step(image, labels_a, labels_b):\n",
    "    with tf.GradientTape() as tape:\n",
    "        probs_a, probs_b = model(image)\n",
    "        loss_a = loss_object(labels_a, probs_a)\n",
    "        loss_b = loss_object(labels_b, probs_b)\n",
    "        loss = loss_a + loss_b\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy_a(labels_a, probs_a)\n",
    "    train_accuracy_b(labels_b, probs_b)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(image, labels_a, labels_b):\n",
    "    probs_a, probs_b = model(image)\n",
    "    t_loss_a = loss_object(labels_a, probs_a)\n",
    "    t_loss_b = loss_object(labels_b, probs_b)\n",
    "    t_loss = t_loss_a + t_loss_b\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy_a(labels_a, probs_a)\n",
    "    test_accuracy_b(labels_b, probs_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for index, (batch_luminance, batch_ab) in tqdm(enumerate(get_dataset()), total=60000//32):\n",
    "        train_step(batch_luminance, batch_ab[:, 0, :, : , :], batch_ab[:, 1, :, : , :])\n",
    "        if index % 100 == 0:\n",
    "            template = 'Epoch {}, Step {}, Loss: {}, Accuracy a: {}, Accuracy b: {}'\n",
    "            print(template.format(epoch+1,\n",
    "                                  index,\n",
    "                                  round(float(train_loss.result()), 3),\n",
    "                                  round(float(train_accuracy_a.result()) * 100, 2),\n",
    "                                  round(float(train_accuracy_b.result()) * 100, 2)))\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy a: {}, Accuracy b: {}'\n",
    "    print(template.format(epoch + 1,\n",
    "                          round(float(train_loss.result()), 3),\n",
    "                          round(float(train_accuracy_a.result()) * 100, 2),\n",
    "                          round(float(train_accuracy_b.result()) * 100, 2)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [data for data in test.shuffle(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[np.random.randint(0, 2000)]\n",
    "feature, labels = pre_process(image)\n",
    "plt.imshow(feature[:, :, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(image, labels_a, labels_b):\n",
    "    probs_a, probs_b = model(image)\n",
    "    t_loss_a = loss_object(labels_a, probs_a)\n",
    "    t_loss_b = loss_object(labels_b, probs_b)\n",
    "    t_loss = t_loss_a + t_loss_b\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy_a(labels_a, probs_a)\n",
    "    test_accuracy_b(labels_b, probs_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_step(np.array([feature], np.float32),\n",
    "          np.array([labels[0]], np.float32),\n",
    "          np.array([labels[1]], np.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_a, probs_b = model(np.array([feature], np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.argmax(probs_a[0], axis=-1)\n",
    "b = tf.argmax(probs_b[0], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_image = process_output(feature[:, :, 0], (a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(np.array(image[\"image\"]))\n",
    "plt.title(\"ground truth\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(feature[:, :, 0], cmap=\"gray\")\n",
    "plt.title(\"gray scale image\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(final_image)\n",
    "plt.title(\"model output\")\n",
    "\n",
    "plt.savefig(\"C:/Users/louis/Documents/3A_berkeley/spring_semester/242/PROJECT/early_results/{}\".format(save_index))\n",
    "save_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_index -= 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {
    "0147cb22559b43c18afe5a0cce6acad9": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "028e944442504e799d8635af32f4c09f": {
     "views": []
    },
    "04f53bfc65d2429eb4ca44a549acfc32": {
     "views": []
    },
    "0713d770945a424b81d3975ed7aef491": {
     "views": []
    },
    "0ed91fa1bdea4b6d98667ace52928001": {
     "views": []
    },
    "17693964e6394f0eb09cff89185736b5": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "1db411dfe55a4444b47e422fa623bdae": {
     "views": []
    },
    "22d50329e9ad4f5d948f252badd021d6": {
     "views": []
    },
    "2ee500d0074c40d98e64e945614d5e67": {
     "views": []
    },
    "316e527b023c43ea861dd433dd9ea96c": {
     "views": []
    },
    "330a9311e50f41c7a069a0af4071493e": {
     "views": []
    },
    "347016f587a94fb8a4aed9828d8783de": {
     "views": []
    },
    "3b061e2063694400a7954db7346b8d57": {
     "views": []
    },
    "40800b8563ed480494d80f8279a74912": {
     "views": []
    },
    "4131e4da77244ebc85f6d251d4df91b7": {
     "views": []
    },
    "4d26f5df3be844d5bf88726f963d67cb": {
     "views": []
    },
    "547795a194e54c2a96c3837dd2ad8a1e": {
     "views": []
    },
    "547ed2036afd43538e8b8a39be7e4d8b": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "58dca577326f49b18e02ef5e6ac23e23": {
     "views": []
    },
    "5f7bd08f711b4886b9491bb84fdc427b": {
     "views": []
    },
    "61b9b29357bc446fbe5e64843fa2043b": {
     "views": []
    },
    "68a740465b8b4d8cbf8c7363a1413225": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "7aa63f0a8c5a425983afa4655dfd60c4": {
     "views": []
    },
    "833c3fa1a2064ab1b41ed08a89800126": {
     "views": []
    },
    "9320492bba0548e1811f9cf0b4106e41": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "9937c84e64b746939af2f711b446b66d": {
     "views": []
    },
    "af26e58380c84a22a7ca9ad5ff157d83": {
     "views": []
    },
    "b1c64e4c97a4465f985c57057ab61cb7": {
     "views": []
    },
    "b32dbbb49cd8429ba677ec5071139f56": {
     "views": []
    },
    "b6e18150b870445a99e73cc01e4968f4": {
     "views": []
    },
    "b86181b0a87f4e348e4e781c4d0aaf74": {
     "views": []
    },
    "baebfca472d54aff8940f30059236c37": {
     "views": []
    },
    "c4db7834011d48debe577117b47083d2": {
     "views": []
    },
    "d117ac2e63ae45afa45ae1de20ce7c80": {
     "views": []
    },
    "d49c96313df8443290cd445efdbb8e0d": {
     "views": []
    },
    "d51c9ae90808424bb61d4f1406fb9ff1": {
     "views": []
    },
    "d6527c5b00394416adb391a9a6976d86": {
     "views": []
    },
    "d836eb685c9d4f6e9ceba772b9f7f186": {
     "views": []
    },
    "e285fca870b44eef8dd6e182faefb32c": {
     "views": []
    },
    "e4df7ec81fa64386b69e7182db2bd10c": {
     "views": []
    },
    "e87b7193198142f78bc80d03d10013fb": {
     "views": []
    },
    "fd166c2de5f4410baba14eb8c8bb529f": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
