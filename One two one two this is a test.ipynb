{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from copy import copy, deepcopy\n",
    "from utils import data_generator, pre_process, process_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = \"patch_images/train\"\n",
    "\n",
    "image_paths = [IMAGE_FOLDER + \"/\" + name for _,_,files in os.walk(IMAGE_FOLDER) for name in files]\n",
    "gen = data_generator(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#123456789\n",
    "n_bins = 313\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # (batch_size, 256, 256, 1) --> (batch_size, 128, 128, 64)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3,\n",
    "                                            strides=(2, 2),\n",
    "                                            padding='same',\n",
    "                                            activation='relu',\n",
    "                                            input_shape=(32, 32, 1))\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # (batch_size, 128, 128, 64) --> (batch_size, 64, 64, 128)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=128, kernel_size=3,\n",
    "                                            strides=(2, 2),\n",
    "                                            padding='same',\n",
    "                                            activation='relu')\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        \n",
    "        # (batch_size, 64, 64, 128)  --> (batch_size, 32, 32, 256)\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=256, kernel_size=3,\n",
    "                                            strides=(2, 2),\n",
    "                                            padding='same',\n",
    "                                            activation='relu')\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # (batch_size, 32, 32, 256) --> (batch_size, 32, 32, 512)\n",
    "        self.conv4 = tf.keras.layers.Conv2D(filters=512, kernel_size=3,\n",
    "                                            strides=(1, 1),\n",
    "                                            dilation_rate=(1, 1),\n",
    "                                            padding='same',\n",
    "                                            activation='relu'),\n",
    "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # (batch_size, 32, 32, 512) --> (batch_size, 32, 32, 512)\n",
    "        self.deconv1 = tf.keras.layers.Conv2DTranspose(filters=512, kernel_size=3,\n",
    "                                                       strides=(1, 1),\n",
    "                                                       dilation_rate=(2, 2),\n",
    "                                                       padding='same',\n",
    "                                                       activation='relu')\n",
    "        self.bn5 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # (batch_size, 32, 32, 512) --> (batch_size, 32, 32, 512)\n",
    "        self.deconv2 = tf.keras.layers.Conv2DTranspose(filters=512, kernel_size=3,\n",
    "                                                       dilation_rate=(2, 2),\n",
    "                                                       padding='same',\n",
    "                                                       activation='relu')\n",
    "        self.bn6 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # (batch_size, 32, 32, 512) --> (batch_size, 32, 32, 512)\n",
    "        self.deconv3 = tf.keras.layers.Conv2DTranspose(filters=512, kernel_size=3,\n",
    "                                                       dilation_rate=(1, 1),\n",
    "                                                       padding='same',\n",
    "                                                       activation='relu')\n",
    "        self.bn7 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # (batch_size, 64, 64, 256) --> (batch_size, 64, 64, n_bins)\n",
    "        self.deconv_a = tf.keras.layers.Conv2DTranspose(filters=n_bins, kernel_size=1,\n",
    "                                                        activation='softmax',\n",
    "                                                        dilation_rate=(1, 1))\n",
    "        self.deconv_b = tf.keras.layers.Conv2DTranspose(filters=n_bins, kernel_size=1,\n",
    "                                                        activation='softmax',\n",
    "                                                        dilation_rate=(1, 1))\n",
    "        \n",
    "        self.seq_layers = [self.conv1, self.bn1,\n",
    "                           self.conv2, self.bn2,\n",
    "                           self.conv3, self.bn3,\n",
    "                           self.conv4, self.bn4,\n",
    "                           self.deconv1, self.bn5,\n",
    "                           self.deconv2, self.bn6,\n",
    "                           self.deconv3, self.bn7]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.seq_layers:\n",
    "            x = layer(x)\n",
    "        probs_a = self.deconv_a(x)\n",
    "        probs_b = self.deconv_b(x)\n",
    "        return probs_a, probs_b\n",
    "        \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0429 14:07:09.013457 4327654848 deprecation.py:323] From /Users/reniel96/anaconda3/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py:410: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "data = tf.data.Dataset.from_generator(lambda: data_generator(image_paths),\n",
    "                                          output_types=(np.float32, np.int64))\n",
    "data = data.shuffle(1000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: (<unknown>, <unknown>), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy_a = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy_a')\n",
    "train_accuracy_b = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy_b')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy_a = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy_a')\n",
    "test_accuracy_b = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy_b')\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "@tf.function\n",
    "def train_step(image, labels_a, labels_b):\n",
    "    with tf.GradientTape() as tape:\n",
    "        probs_a, probs_b = model(image)\n",
    "        loss_a = loss_object(labels_a, probs_a)\n",
    "        loss_b = loss_object(labels_b, probs_b)\n",
    "        loss = loss_a + loss_b\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy_a(labels_a, probs_a)\n",
    "    train_accuracy_b(labels_b, probs_b)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(image, labels_a, labels_b):\n",
    "    probs_a, probs_b = model(image)\n",
    "    t_loss_a = loss_object(labels_a, probs_a)\n",
    "    t_loss_b = loss_object(labels_b, probs_b)\n",
    "    t_loss = t_loss_a + t_loss_b\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy_a(labels_a, probs_a)\n",
    "    test_accuracy_b(labels_b, probs_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "TypeError: 'NoneType' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"/Users/reniel96/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/script_ops.py\", line 207, in __call__\n    ret = func(*args)\n\n  File \"/Users/reniel96/anaconda3/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 430, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/Users/reniel96/Desktop/Berkeley/Spring Semester/IEOR 242/IEOR242_deep_colorization/utils.py\", line 77, in data_generator\n    rgb_image = bgr_image[:, :, ::-1]\n\nTypeError: 'NoneType' object is not subscriptable\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNextSync]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c2eec9e931fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_luminance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_luminance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \"\"\"\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   1952\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: TypeError: 'NoneType' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"/Users/reniel96/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/script_ops.py\", line 207, in __call__\n    ret = func(*args)\n\n  File \"/Users/reniel96/anaconda3/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 430, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/Users/reniel96/Desktop/Berkeley/Spring Semester/IEOR 242/IEOR242_deep_colorization/utils.py\", line 77, in data_generator\n    rgb_image = bgr_image[:, :, ::-1]\n\nTypeError: 'NoneType' object is not subscriptable\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNextSync]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for index, (batch_luminance, batch_ab) in tqdm(enumerate(data), total=1000//32):\n",
    "        train_step(batch_luminance, batch_ab[:, 0, :, : , :], batch_ab[:, 1, :, : , :])\n",
    "        if index % 100 == 0:\n",
    "            template = 'Epoch {}, Step {}, Loss: {}, Accuracy a: {}, Accuracy b: {}'\n",
    "            print(template.format(epoch+1,\n",
    "                                  index,\n",
    "                                  round(float(train_loss.result()), 3),\n",
    "                                  round(float(train_accuracy_a.result()) * 100, 2),\n",
    "                                  round(float(train_accuracy_b.result()) * 100, 2)))\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy a: {}, Accuracy b: {}'\n",
    "    print(template.format(epoch + 1,\n",
    "                          round(float(train_loss.result()), 3),\n",
    "                          round(float(train_accuracy_a.result()) * 100, 2),\n",
    "                          round(float(train_accuracy_b.result()) * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
